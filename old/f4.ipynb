{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "mounted-farming",
   "metadata": {},
   "source": [
    "# Financial Time-Series Forecasting Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "burning-chassis",
   "metadata": {},
   "source": [
    "### Data Import & Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "grand-present",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-monte",
   "metadata": {},
   "source": [
    "To make this notebook's output stable across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "premium-disaster",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-savannah",
   "metadata": {},
   "source": [
    "Importing test and train dataset, using `os.getcwd()` to get current working directory and then finding the .csv(s) in the `data` subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "public-seller",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(os.getcwd()+\"/data/test.csv\")\n",
    "train =pd.read_csv(os.getcwd()+\"/data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-deadline",
   "metadata": {},
   "source": [
    "Using `.head()` to preview train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "demographic-berry",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>w</th>\n",
       "      <th>y</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.483130</td>\n",
       "      <td>0.790980</td>\n",
       "      <td>0.702555</td>\n",
       "      <td>0.528220</td>\n",
       "      <td>0.298746</td>\n",
       "      <td>0.025488</td>\n",
       "      <td>-0.173480</td>\n",
       "      <td>-0.245290</td>\n",
       "      <td>-0.405057</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954288</td>\n",
       "      <td>1.143901</td>\n",
       "      <td>1.359252</td>\n",
       "      <td>1.081061</td>\n",
       "      <td>1.364409</td>\n",
       "      <td>1.449354</td>\n",
       "      <td>1.195431</td>\n",
       "      <td>1.195992</td>\n",
       "      <td>1.165327</td>\n",
       "      <td>0.771110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.135624</td>\n",
       "      <td>0.765286</td>\n",
       "      <td>0.604512</td>\n",
       "      <td>0.414197</td>\n",
       "      <td>0.241638</td>\n",
       "      <td>0.181862</td>\n",
       "      <td>-0.031920</td>\n",
       "      <td>-0.070617</td>\n",
       "      <td>-0.185980</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561545</td>\n",
       "      <td>0.678086</td>\n",
       "      <td>0.848950</td>\n",
       "      <td>1.133852</td>\n",
       "      <td>1.041396</td>\n",
       "      <td>1.242806</td>\n",
       "      <td>1.248121</td>\n",
       "      <td>1.331348</td>\n",
       "      <td>1.267123</td>\n",
       "      <td>1.292718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.686081</td>\n",
       "      <td>0.702834</td>\n",
       "      <td>0.637708</td>\n",
       "      <td>0.798416</td>\n",
       "      <td>0.755065</td>\n",
       "      <td>0.705225</td>\n",
       "      <td>0.535391</td>\n",
       "      <td>0.613129</td>\n",
       "      <td>0.549732</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328694</td>\n",
       "      <td>1.324254</td>\n",
       "      <td>1.272889</td>\n",
       "      <td>1.074786</td>\n",
       "      <td>0.753950</td>\n",
       "      <td>0.539693</td>\n",
       "      <td>0.402041</td>\n",
       "      <td>0.442759</td>\n",
       "      <td>0.487557</td>\n",
       "      <td>0.699007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.342005</td>\n",
       "      <td>0.018378</td>\n",
       "      <td>-0.097297</td>\n",
       "      <td>-0.020850</td>\n",
       "      <td>-0.083325</td>\n",
       "      <td>-0.268512</td>\n",
       "      <td>-0.486335</td>\n",
       "      <td>-0.731130</td>\n",
       "      <td>-0.924458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386676</td>\n",
       "      <td>-0.357946</td>\n",
       "      <td>-0.612069</td>\n",
       "      <td>-0.698063</td>\n",
       "      <td>-0.891789</td>\n",
       "      <td>-1.127624</td>\n",
       "      <td>-1.535678</td>\n",
       "      <td>-1.490786</td>\n",
       "      <td>-1.856840</td>\n",
       "      <td>-1.441472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.241418</td>\n",
       "      <td>0.463120</td>\n",
       "      <td>0.665307</td>\n",
       "      <td>0.446953</td>\n",
       "      <td>0.480780</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.309231</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.190963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174944</td>\n",
       "      <td>-0.529541</td>\n",
       "      <td>-0.191921</td>\n",
       "      <td>-0.258093</td>\n",
       "      <td>-0.542403</td>\n",
       "      <td>-0.414866</td>\n",
       "      <td>-0.485580</td>\n",
       "      <td>-0.768820</td>\n",
       "      <td>-0.662573</td>\n",
       "      <td>-0.211837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   w         y         0         1         2         3         4         5  \\\n",
       "0  1  0.483130  0.790980  0.702555  0.528220  0.298746  0.025488 -0.173480   \n",
       "1  1  1.135624  0.765286  0.604512  0.414197  0.241638  0.181862 -0.031920   \n",
       "2  1  0.686081  0.702834  0.637708  0.798416  0.755065  0.705225  0.535391   \n",
       "3  1 -1.342005  0.018378 -0.097297 -0.020850 -0.083325 -0.268512 -0.486335   \n",
       "4  1 -0.241418  0.463120  0.665307  0.446953  0.480780  0.392500  0.309231   \n",
       "\n",
       "          6         7  ...        40        41        42        43        44  \\\n",
       "0 -0.245290 -0.405057  ...  0.954288  1.143901  1.359252  1.081061  1.364409   \n",
       "1 -0.070617 -0.185980  ...  0.561545  0.678086  0.848950  1.133852  1.041396   \n",
       "2  0.613129  0.549732  ...  1.328694  1.324254  1.272889  1.074786  0.753950   \n",
       "3 -0.731130 -0.924458  ... -0.386676 -0.357946 -0.612069 -0.698063 -0.891789   \n",
       "4  0.158462  0.190963  ... -0.174944 -0.529541 -0.191921 -0.258093 -0.542403   \n",
       "\n",
       "         45        46        47        48        49  \n",
       "0  1.449354  1.195431  1.195992  1.165327  0.771110  \n",
       "1  1.242806  1.248121  1.331348  1.267123  1.292718  \n",
       "2  0.539693  0.402041  0.442759  0.487557  0.699007  \n",
       "3 -1.127624 -1.535678 -1.490786 -1.856840 -1.441472  \n",
       "4 -0.414866 -0.485580 -0.768820 -0.662573 -0.211837  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "average-sample",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.670595</td>\n",
       "      <td>-0.839068</td>\n",
       "      <td>-0.734415</td>\n",
       "      <td>-0.587261</td>\n",
       "      <td>-0.788800</td>\n",
       "      <td>-0.975857</td>\n",
       "      <td>-0.774088</td>\n",
       "      <td>-1.021334</td>\n",
       "      <td>-1.110286</td>\n",
       "      <td>-0.893337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.997627</td>\n",
       "      <td>-1.103794</td>\n",
       "      <td>-1.092988</td>\n",
       "      <td>-0.989165</td>\n",
       "      <td>-0.827528</td>\n",
       "      <td>-0.813729</td>\n",
       "      <td>-0.532411</td>\n",
       "      <td>-0.289483</td>\n",
       "      <td>-0.407720</td>\n",
       "      <td>-0.407505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.188165</td>\n",
       "      <td>0.166410</td>\n",
       "      <td>0.321011</td>\n",
       "      <td>0.318078</td>\n",
       "      <td>0.641710</td>\n",
       "      <td>0.951932</td>\n",
       "      <td>1.170069</td>\n",
       "      <td>1.177711</td>\n",
       "      <td>0.987763</td>\n",
       "      <td>0.981345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.743405</td>\n",
       "      <td>0.916254</td>\n",
       "      <td>0.866453</td>\n",
       "      <td>0.953677</td>\n",
       "      <td>0.716259</td>\n",
       "      <td>0.692816</td>\n",
       "      <td>0.446713</td>\n",
       "      <td>0.539733</td>\n",
       "      <td>0.279293</td>\n",
       "      <td>0.180641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.886510</td>\n",
       "      <td>0.760716</td>\n",
       "      <td>0.751800</td>\n",
       "      <td>0.052198</td>\n",
       "      <td>-0.050958</td>\n",
       "      <td>-0.140734</td>\n",
       "      <td>-0.173480</td>\n",
       "      <td>0.178508</td>\n",
       "      <td>0.198187</td>\n",
       "      <td>0.357906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.444142</td>\n",
       "      <td>0.492294</td>\n",
       "      <td>0.573348</td>\n",
       "      <td>0.546323</td>\n",
       "      <td>0.373874</td>\n",
       "      <td>0.699132</td>\n",
       "      <td>0.808303</td>\n",
       "      <td>1.118522</td>\n",
       "      <td>1.284887</td>\n",
       "      <td>1.541929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.187722</td>\n",
       "      <td>0.030199</td>\n",
       "      <td>-0.072558</td>\n",
       "      <td>-0.098400</td>\n",
       "      <td>-0.110795</td>\n",
       "      <td>-0.127632</td>\n",
       "      <td>-0.241193</td>\n",
       "      <td>-0.374608</td>\n",
       "      <td>-0.651771</td>\n",
       "      <td>-0.513491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.340927</td>\n",
       "      <td>-0.268253</td>\n",
       "      <td>-0.654777</td>\n",
       "      <td>-1.133722</td>\n",
       "      <td>-1.484557</td>\n",
       "      <td>-1.446644</td>\n",
       "      <td>-1.654337</td>\n",
       "      <td>-1.521009</td>\n",
       "      <td>-1.593825</td>\n",
       "      <td>-1.110684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.248822</td>\n",
       "      <td>0.168815</td>\n",
       "      <td>0.260804</td>\n",
       "      <td>0.505885</td>\n",
       "      <td>0.471486</td>\n",
       "      <td>1.018661</td>\n",
       "      <td>0.971406</td>\n",
       "      <td>1.062348</td>\n",
       "      <td>0.986871</td>\n",
       "      <td>0.947982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422044</td>\n",
       "      <td>0.688196</td>\n",
       "      <td>0.382416</td>\n",
       "      <td>0.344843</td>\n",
       "      <td>0.177595</td>\n",
       "      <td>0.330549</td>\n",
       "      <td>0.595061</td>\n",
       "      <td>0.884860</td>\n",
       "      <td>1.125103</td>\n",
       "      <td>1.220779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.670595 -0.839068 -0.734415 -0.587261 -0.788800 -0.975857 -0.774088   \n",
       "1  0.188165  0.166410  0.321011  0.318078  0.641710  0.951932  1.170069   \n",
       "2  0.886510  0.760716  0.751800  0.052198 -0.050958 -0.140734 -0.173480   \n",
       "3 -0.187722  0.030199 -0.072558 -0.098400 -0.110795 -0.127632 -0.241193   \n",
       "4  0.248822  0.168815  0.260804  0.505885  0.471486  1.018661  0.971406   \n",
       "\n",
       "          7         8         9  ...        40        41        42        43  \\\n",
       "0 -1.021334 -1.110286 -0.893337  ... -0.997627 -1.103794 -1.092988 -0.989165   \n",
       "1  1.177711  0.987763  0.981345  ...  0.743405  0.916254  0.866453  0.953677   \n",
       "2  0.178508  0.198187  0.357906  ...  0.444142  0.492294  0.573348  0.546323   \n",
       "3 -0.374608 -0.651771 -0.513491  ... -0.340927 -0.268253 -0.654777 -1.133722   \n",
       "4  1.062348  0.986871  0.947982  ...  0.422044  0.688196  0.382416  0.344843   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0 -0.827528 -0.813729 -0.532411 -0.289483 -0.407720 -0.407505  \n",
       "1  0.716259  0.692816  0.446713  0.539733  0.279293  0.180641  \n",
       "2  0.373874  0.699132  0.808303  1.118522  1.284887  1.541929  \n",
       "3 -1.484557 -1.446644 -1.654337 -1.521009 -1.593825 -1.110684  \n",
       "4  0.177595  0.330549  0.595061  0.884860  1.125103  1.220779  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-shipping",
   "metadata": {},
   "source": [
    "We now drop the `y` label (that is the one that we'll predict) from the training set and also `w` that is useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "urban-satisfaction",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.790980</td>\n",
       "      <td>0.702555</td>\n",
       "      <td>0.528220</td>\n",
       "      <td>0.298746</td>\n",
       "      <td>0.025488</td>\n",
       "      <td>-0.173480</td>\n",
       "      <td>-0.245290</td>\n",
       "      <td>-0.405057</td>\n",
       "      <td>-0.371818</td>\n",
       "      <td>-0.032334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.954288</td>\n",
       "      <td>1.143901</td>\n",
       "      <td>1.359252</td>\n",
       "      <td>1.081061</td>\n",
       "      <td>1.364409</td>\n",
       "      <td>1.449354</td>\n",
       "      <td>1.195431</td>\n",
       "      <td>1.195992</td>\n",
       "      <td>1.165327</td>\n",
       "      <td>0.771110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.765286</td>\n",
       "      <td>0.604512</td>\n",
       "      <td>0.414197</td>\n",
       "      <td>0.241638</td>\n",
       "      <td>0.181862</td>\n",
       "      <td>-0.031920</td>\n",
       "      <td>-0.070617</td>\n",
       "      <td>-0.185980</td>\n",
       "      <td>-0.188546</td>\n",
       "      <td>0.275131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561545</td>\n",
       "      <td>0.678086</td>\n",
       "      <td>0.848950</td>\n",
       "      <td>1.133852</td>\n",
       "      <td>1.041396</td>\n",
       "      <td>1.242806</td>\n",
       "      <td>1.248121</td>\n",
       "      <td>1.331348</td>\n",
       "      <td>1.267123</td>\n",
       "      <td>1.292718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.702834</td>\n",
       "      <td>0.637708</td>\n",
       "      <td>0.798416</td>\n",
       "      <td>0.755065</td>\n",
       "      <td>0.705225</td>\n",
       "      <td>0.535391</td>\n",
       "      <td>0.613129</td>\n",
       "      <td>0.549732</td>\n",
       "      <td>0.472387</td>\n",
       "      <td>0.431216</td>\n",
       "      <td>...</td>\n",
       "      <td>1.328694</td>\n",
       "      <td>1.324254</td>\n",
       "      <td>1.272889</td>\n",
       "      <td>1.074786</td>\n",
       "      <td>0.753950</td>\n",
       "      <td>0.539693</td>\n",
       "      <td>0.402041</td>\n",
       "      <td>0.442759</td>\n",
       "      <td>0.487557</td>\n",
       "      <td>0.699007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018378</td>\n",
       "      <td>-0.097297</td>\n",
       "      <td>-0.020850</td>\n",
       "      <td>-0.083325</td>\n",
       "      <td>-0.268512</td>\n",
       "      <td>-0.486335</td>\n",
       "      <td>-0.731130</td>\n",
       "      <td>-0.924458</td>\n",
       "      <td>-0.995159</td>\n",
       "      <td>-1.352881</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.386676</td>\n",
       "      <td>-0.357946</td>\n",
       "      <td>-0.612069</td>\n",
       "      <td>-0.698063</td>\n",
       "      <td>-0.891789</td>\n",
       "      <td>-1.127624</td>\n",
       "      <td>-1.535678</td>\n",
       "      <td>-1.490786</td>\n",
       "      <td>-1.856840</td>\n",
       "      <td>-1.441472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.463120</td>\n",
       "      <td>0.665307</td>\n",
       "      <td>0.446953</td>\n",
       "      <td>0.480780</td>\n",
       "      <td>0.392500</td>\n",
       "      <td>0.309231</td>\n",
       "      <td>0.158462</td>\n",
       "      <td>0.190963</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.198676</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174944</td>\n",
       "      <td>-0.529541</td>\n",
       "      <td>-0.191921</td>\n",
       "      <td>-0.258093</td>\n",
       "      <td>-0.542403</td>\n",
       "      <td>-0.414866</td>\n",
       "      <td>-0.485580</td>\n",
       "      <td>-0.768820</td>\n",
       "      <td>-0.662573</td>\n",
       "      <td>-0.211837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.790980  0.702555  0.528220  0.298746  0.025488 -0.173480 -0.245290   \n",
       "1  0.765286  0.604512  0.414197  0.241638  0.181862 -0.031920 -0.070617   \n",
       "2  0.702834  0.637708  0.798416  0.755065  0.705225  0.535391  0.613129   \n",
       "3  0.018378 -0.097297 -0.020850 -0.083325 -0.268512 -0.486335 -0.731130   \n",
       "4  0.463120  0.665307  0.446953  0.480780  0.392500  0.309231  0.158462   \n",
       "\n",
       "          7         8         9  ...        40        41        42        43  \\\n",
       "0 -0.405057 -0.371818 -0.032334  ...  0.954288  1.143901  1.359252  1.081061   \n",
       "1 -0.185980 -0.188546  0.275131  ...  0.561545  0.678086  0.848950  1.133852   \n",
       "2  0.549732  0.472387  0.431216  ...  1.328694  1.324254  1.272889  1.074786   \n",
       "3 -0.924458 -0.995159 -1.352881  ... -0.386676 -0.357946 -0.612069 -0.698063   \n",
       "4  0.190963  0.273600  0.198676  ... -0.174944 -0.529541 -0.191921 -0.258093   \n",
       "\n",
       "         44        45        46        47        48        49  \n",
       "0  1.364409  1.449354  1.195431  1.195992  1.165327  0.771110  \n",
       "1  1.041396  1.242806  1.248121  1.331348  1.267123  1.292718  \n",
       "2  0.753950  0.539693  0.402041  0.442759  0.487557  0.699007  \n",
       "3 -0.891789 -1.127624 -1.535678 -1.490786 -1.856840 -1.441472  \n",
       "4 -0.542403 -0.414866 -0.485580 -0.768820 -0.662573 -0.211837  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_train = train.drop([\"y\", \"w\"], axis=1)\n",
    "\n",
    "y = train[\"y\"].copy()\n",
    "financial_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-wrestling",
   "metadata": {},
   "source": [
    "We now check so that for `null` values in the dataset.\n",
    "\n",
    "We could also use `.info()` to have more information like the Dtypes of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "exclusive-stopping",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "financial_train.isnull().values.any()\n",
    "#financial_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "favorite-chance",
   "metadata": {},
   "source": [
    "We now print the mean and the standard deviation for `financial_train` and after the plot for the correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "royal-atlanta",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:\n",
      "\n",
      "[0.01690311 0.01897392 0.02320434 0.02763826 0.03106758 0.03990432\n",
      " 0.04564649 0.05125901 0.05523723 0.05998229 0.06348559 0.06059931\n",
      " 0.0595254  0.05751156 0.05432058 0.04932228 0.04643498 0.04403553\n",
      " 0.0406522  0.04198718 0.0409172  0.04040852 0.04092458 0.0464065\n",
      " 0.04816842 0.05133673 0.05514936 0.05567795 0.05729535 0.05941809\n",
      " 0.05451284 0.05246735 0.05084397 0.04789078 0.04369453 0.04131472\n",
      " 0.03917703 0.03669292 0.03443982 0.0305863  0.03662203 0.03902369\n",
      " 0.04360521 0.04540032 0.04947673 0.05575918 0.06071495 0.07043613\n",
      " 0.07828405 0.08102811] \n",
      "\n",
      " std: \n",
      "\n",
      "[0.52541053 0.52491514 0.52848951 0.53464913 0.53880475 0.5417865\n",
      " 0.54870909 0.55419235 0.55770326 0.56149684 0.560994   0.56543377\n",
      " 0.56992756 0.57350887 0.57712409 0.57916214 0.58666059 0.58964479\n",
      " 0.5969637  0.60356411 0.60950638 0.6191625  0.62788191 0.63977145\n",
      " 0.64798546 0.65465379 0.66365014 0.66996123 0.67578322 0.68552744\n",
      " 0.6940925  0.70205383 0.71153066 0.71805973 0.72637984 0.73511858\n",
      " 0.74174153 0.74887765 0.7607051  0.77048763 0.77962479 0.79185982\n",
      " 0.80142961 0.81351217 0.82554335 0.8329938  0.84780252 0.86211745\n",
      " 0.88122666 0.89348236]\n"
     ]
    }
   ],
   "source": [
    "mean = np.array(financial_train.mean(axis=0))\n",
    "std = np.array(financial_train.std(axis=0))\n",
    "print(f\"mean:\\n\\n{mean} \\n\\n std: \\n\\n{std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "passive-clerk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(financial_train.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-necessity",
   "metadata": {},
   "source": [
    "We now do a summary print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "demanding-shuttle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3        4        5        6  \\\n",
      "count  7.33e+03  7.33e+03  7.33e+03  7.33e+03  7326.00  7326.00  7326.00   \n",
      "mean   1.69e-02  1.90e-02  2.32e-02  2.76e-02     0.03     0.04     0.05   \n",
      "std    5.25e-01  5.25e-01  5.28e-01  5.35e-01     0.54     0.54     0.55   \n",
      "min   -1.26e+00 -1.27e+00 -1.27e+00 -1.26e+00    -1.33    -1.28    -1.36   \n",
      "25%   -3.67e-01 -3.61e-01 -3.59e-01 -3.67e-01    -0.37    -0.35    -0.35   \n",
      "50%   -3.59e-03 -1.57e-03  2.99e-03  9.82e-03     0.02     0.03     0.03   \n",
      "75%    3.85e-01  3.80e-01  3.87e-01  4.10e-01     0.43     0.44     0.44   \n",
      "max    1.39e+00  1.41e+00  1.42e+00  1.44e+00     1.39     1.38     1.41   \n",
      "\n",
      "             7        8        9  ...       40       41       42       43  \\\n",
      "count  7326.00  7326.00  7326.00  ...  7326.00  7326.00  7326.00  7326.00   \n",
      "mean      0.05     0.06     0.06  ...     0.04     0.04     0.04     0.05   \n",
      "std       0.55     0.56     0.56  ...     0.78     0.79     0.80     0.81   \n",
      "min      -1.29    -1.29    -1.37  ...    -1.76    -1.76    -1.76    -1.80   \n",
      "25%      -0.35    -0.34    -0.33  ...    -0.56    -0.56    -0.56    -0.57   \n",
      "50%       0.05     0.05     0.05  ...     0.07     0.08     0.09     0.10   \n",
      "75%       0.47     0.47     0.48  ...     0.63     0.66     0.67     0.69   \n",
      "max       1.40     1.38     1.38  ...     1.77     1.78     1.74     1.73   \n",
      "\n",
      "            44       45       46       47       48       49  \n",
      "count  7326.00  7326.00  7326.00  7326.00  7326.00  7326.00  \n",
      "mean      0.05     0.06     0.06     0.07     0.08     0.08  \n",
      "std       0.83     0.83     0.85     0.86     0.88     0.89  \n",
      "min      -1.87    -1.79    -1.86    -1.89    -1.94    -1.84  \n",
      "25%      -0.58    -0.58    -0.60    -0.61    -0.61    -0.63  \n",
      "50%       0.11     0.13     0.12     0.13     0.15     0.14  \n",
      "75%       0.70     0.72     0.75     0.77     0.81     0.82  \n",
      "max       1.76     1.82     1.87     1.90     1.93     1.87  \n",
      "\n",
      "[8 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('precision', 2)\n",
    "print(financial_train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-above",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-milton",
   "metadata": {},
   "source": [
    "We now use `StandardScaler` from `sklearn.preprocessing` to standardize features by removing the mean and scaling to unit variance.\n",
    "\n",
    "The standard score of a sample x is calculated as: $z = \\frac{x-\\mu}{\\sigma}$\n",
    "\n",
    "where $\\mu$ is the mean of the training samples and $\\sigma$ is the standard deviation of the training samples. Then it's printed the first element of the standardized training set that is `fin_train_tr`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "floating-complex",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.47338019,  1.30235825,  0.95564801,  0.50711092, -0.01035549,\n",
       "       -0.39387997, -0.5302557 , -0.82344513, -0.76579133, -0.16442222,\n",
       "        0.13738692,  0.583178  ,  0.63846677,  0.65639649,  0.63737201,\n",
       "        0.88648875,  1.15512339,  1.40222914,  1.27671247,  1.20540183,\n",
       "        1.41247976,  1.5211402 ,  1.61250985,  1.74262046,  1.54044274,\n",
       "        1.02274007,  0.7181615 ,  0.23427535, -0.16626768,  0.1978177 ,\n",
       "       -0.40068443, -0.20931982,  0.51195996,  0.51298375,  0.59917762,\n",
       "        1.04173587,  1.18806649,  0.98412464,  1.12846276,  1.34941833,\n",
       "        1.17714117,  1.3953899 ,  1.64173646,  1.27315984,  1.59291723,\n",
       "        1.67310954,  1.33851173,  1.30566091,  1.23364047,  0.7724038 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "#print(scaler.fit(financial_train))\n",
    "#print(scaler.transform(financial_train))\n",
    "fin_train_tr = scaler.fit_transform(financial_train)\n",
    "fin_train_tr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wound-saudi",
   "metadata": {},
   "source": [
    "And we can check the structure of `fin_train_tr` by looking at it shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "governing-release",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7326, 50)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_train_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-tension",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpine-dressing",
   "metadata": {},
   "source": [
    "Now, the data prepared before are fitted into the linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "competent-estonia",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "reg=lin_reg.fit(fin_train_tr, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-chart",
   "metadata": {},
   "source": [
    "and the coefficients obtained regressing are printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hollywood-prompt",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03344353, -0.0218639 , -0.00479024,  0.01003545,  0.00906221,\n",
       "        0.00337682, -0.02607611, -0.00478668, -0.00922735, -0.00635232,\n",
       "       -0.0164575 ,  0.01184526, -0.0049513 ,  0.00494387,  0.00489573,\n",
       "       -0.01737873,  0.0032157 ,  0.00092394,  0.01924829,  0.02337346,\n",
       "        0.02882373,  0.0328648 ,  0.00446   ,  0.00352186,  0.01412366,\n",
       "        0.00580924,  0.01399462,  0.05154996,  0.03942301,  0.02664389,\n",
       "       -0.01186767,  0.00286495, -0.0028503 ,  0.03214937,  0.0547392 ,\n",
       "        0.06090827,  0.03875844, -0.01538457, -0.04309818, -0.05687409,\n",
       "       -0.00575772,  0.02812204,  0.05595678,  0.03568889, -0.00253793,\n",
       "       -0.13082635, -0.17044395, -0.06741403,  0.24414514,  0.71137959])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-closing",
   "metadata": {},
   "source": [
    "### Error evaluation (on the training set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "knowing-lexington",
   "metadata": {},
   "source": [
    "Firts is computed the MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "photographic-affiliate",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15053862493315537"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "fin_predictions = lin_reg.predict(fin_train_tr)\n",
    "lin_mse = mean_squared_error(y, fin_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distant-madonna",
   "metadata": {},
   "source": [
    "and then MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "organized-clearance",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12126773129689675"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(y, fin_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-gibson",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fitting-disabled",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import auc, accuracy_score, confusion_matrix, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, RandomizedSearchCV, train_test_split\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "entire-freight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0010456557576390536\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train.drop([\"y\", \"w\"],axis=1), train[\"y\"].values, test_size=0.2, random_state=42)\n",
    "\n",
    "XGBRegressor = xgb.XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "       importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=8, min_child_weight=1, missing=None, n_estimators=1000,\n",
    "       n_jobs=1, nthread=None, objective='reg:squarederror', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42,\n",
    "       silent=None, subsample=1, verbosity=1)\n",
    "\n",
    "xgb_model = XGBRegressor\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_model.predict(X_train)\n",
    "\n",
    "\n",
    "mse=mean_squared_error(y_train, y_pred)\n",
    "print(np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-viking",
   "metadata": {},
   "source": [
    "## param optimization - NEED TO BE ADJUSTED! \n",
    "currently produces parameters that are worst than the default one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "mobile-simon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 42 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "/Users/ghiso/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=5)]: Done  40 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=5)]: Done  84 out of  84 | elapsed: 11.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:04:44] WARNING: ../src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "0.9743907731847772\n",
      "{'colsample_bytree': 0.7, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 4, 'n_estimators': 1000, 'nthread': 4, 'objective': 'reg:squarederror', 'silent': 1, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "xgb1 = xgb.XGBRegressor()\n",
    "parameters = {'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              'objective':['reg:squarederror'],\n",
    "              'learning_rate': [0.005, .01, .03, 0.7], #so called `eta` value\n",
    "              'max_depth': [5, 6, 7],\n",
    "              'min_child_weight': [4],\n",
    "              'silent': [1],\n",
    "              'subsample': [0.7],\n",
    "              'colsample_bytree': [0.7],\n",
    "              'n_estimators': [1000]}\n",
    "\n",
    "xgb_grid = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        n_jobs = 5,\n",
    "                        verbose=True)\n",
    "\n",
    "xgb_grid.fit(X_train, y_train)\n",
    "\n",
    "print(xgb_grid.best_score_)\n",
    "print(xgb_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-investigator",
   "metadata": {},
   "source": [
    "### Save file to be submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "checked-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(\"submissions.txt\", y_pred,delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equal-spine",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
